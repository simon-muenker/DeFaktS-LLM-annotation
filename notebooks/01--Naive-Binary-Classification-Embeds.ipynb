{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simon/Repositories/DeFaktS-LLM-annotation/.venv/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import typing\n",
    "\n",
    "import pandas\n",
    "import numpy\n",
    "import sentence_transformers\n",
    "\n",
    "import rich.progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE: str = \"../data/processed/DefaktS_Twitter.binary.csv\"\n",
    "TEST_FRAC: float = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA: pandas.DataFrame = (\n",
    "    pandas.read_csv(DATA_FILE, index_col=[0])\n",
    "    .replace(dict(binary_label={0.0: \"neutral_post\", 1.0: \"possible_fake_news\"}))\n",
    "    .rename(columns={\"binary_label\": \"label\"})\n",
    ")\n",
    "DATA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN = DATA.sample(frac=1.0 - TEST_FRAC)\n",
    "DATA_TEST = DATA.loc[DATA.index.difference(DATA_TRAIN.index)]\n",
    "\n",
    "len(DATA_TRAIN), len(DATA_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sentence_transformers.SentenceTransformer(\"mixedbread-ai/mxbai-embed-large-v1\", device=\"cuda\")\n",
    "\n",
    "def remote_encoding(data: typing.List[str]) -> typing.List:\n",
    "\n",
    "    def batched(iterable, n=64):\n",
    "        l = len(iterable)\n",
    "\n",
    "        return [\n",
    "            iterable[ndx:min(ndx + n, l)]\n",
    "            for ndx in range(0, l, n)\n",
    "        ]\n",
    "\n",
    "    embeds: typing.List[numpy.ndarray] = []\n",
    "\n",
    "    for batch in rich.progress.track(batched(data)):\n",
    "    \n",
    "        try: \n",
    "            embed = model.encode(batch)\n",
    "            \n",
    "        except Exception as _e:\n",
    "            display(_e)\n",
    "            embed = None\n",
    "        \n",
    "        embeds.extend(embed)\n",
    "\n",
    "    return embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODERS: typing.Dict[str, typing.Dict[str, typing.Callable]] = {\n",
    "    \"transformer_embeds\": {\n",
    "        \"embed_train\": lambda x: remote_encoding(x),\n",
    "        \"embed_test\": lambda x: remote_encoding(x),\n",
    "    },\n",
    "    \"tfidf\": {\n",
    "        \"engine\": (tfidf := TfidfVectorizer()),\n",
    "        \"embed_train\": lambda x: tfidf.fit_transform(x),\n",
    "        \"embed_test\": lambda x: tfidf.transform(x),\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFIERS: typing.Dict[str, typing.Callable] = {\n",
    "    \"svc\": LinearSVC,\n",
    "    \"random_forest\": RandomForestClassifier,\n",
    "    \"ada_boost\": AdaBoostClassifier,\n",
    "    \"decision_tree\": DecisionTreeClassifier,\n",
    "    \"k_neighbors\": KNeighborsClassifier,\n",
    "    \"mlp\": MLPClassifier,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results: typing.List[pandas.DataFrame] = []\n",
    "\n",
    "for encoder_label, encoder in ENCODERS.items():\n",
    "\n",
    "    embed_train = encoder[\"embed_train\"](DATA_TRAIN[\"text\"].tolist())\n",
    "    embed_test = encoder[\"embed_test\"](DATA_TEST[\"text\"].tolist())\n",
    "\n",
    "    results.append(\n",
    "        pandas.json_normalize(\n",
    "            data=[\n",
    "                classification_report(\n",
    "                    DATA_TEST[\"label\"].tolist(),\n",
    "                    (\n",
    "                        classifier()\n",
    "                        .fit(\n",
    "                                embed_train, \n",
    "                                DATA_TRAIN[\"label\"].tolist()\n",
    "                            )\n",
    "                        .predict(embed_test)\n",
    "                    ),\n",
    "                    zero_division=1.,\n",
    "                    output_dict=True\n",
    "                ) | {\"classifier\": classifier_label, \"encoder\": encoder_label}\n",
    "                for classifier_label, classifier in CLASSIFIERS.items()\n",
    "            ]\n",
    "        )\n",
    "        .set_index([\"encoder\", \"classifier\"], drop=True)\n",
    "        .filter(\n",
    "            items=[\n",
    "                \"accuracy\",\n",
    "                \"macro avg.f1-score\",\n",
    "                \"weighted avg.f1-score\"\n",
    "            ]\n",
    "        )\n",
    "        .sort_values(by=\"accuracy\", ascending=False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.concat(results).sort_values(by=\"weighted avg.f1-score\", ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
