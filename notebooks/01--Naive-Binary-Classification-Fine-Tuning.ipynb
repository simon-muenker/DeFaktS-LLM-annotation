{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import datasets\n",
    "\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainerCallback,\n",
    ")\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, log_loss\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE: str = \"../data/processed/DefaktS_Twitter.binary.csv\"\n",
    "TEST_FRAC: float = 0.05\n",
    "\n",
    "MODEL_SLUG: str = \"bert-base-german-cased\"\n",
    "\n",
    "OUT_DIR: str = \"./fine_tuning_ouput/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>408378</th>\n",
       "      <td>Wenn chinesische Elektro-Fahrzeuge auf den deu...</td>\n",
       "      <td>neutral_post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389814</th>\n",
       "      <td>Fahrplan bis 2030: #Bundeskanzler will Windkra...</td>\n",
       "      <td>neutral_post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378444</th>\n",
       "      <td>#Pr√§sident Joe #Biden stelle die Position der ...</td>\n",
       "      <td>neutral_post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390255</th>\n",
       "      <td>#NichtGenesen: Neue Wege f√ºr die #MECFS-Forsch...</td>\n",
       "      <td>neutral_post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409315</th>\n",
       "      <td>BREAKING: Erdogan nennt dieses Erdbeben die gr...</td>\n",
       "      <td>neutral_post</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text         label\n",
       "id                                                                     \n",
       "408378  Wenn chinesische Elektro-Fahrzeuge auf den deu...  neutral_post\n",
       "389814  Fahrplan bis 2030: #Bundeskanzler will Windkra...  neutral_post\n",
       "378444  #Pr√§sident Joe #Biden stelle die Position der ...  neutral_post\n",
       "390255  #NichtGenesen: Neue Wege f√ºr die #MECFS-Forsch...  neutral_post\n",
       "409315  BREAKING: Erdogan nennt dieses Erdbeben die gr...  neutral_post"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA: pandas.DataFrame = (\n",
    "    pandas.read_csv(DATA_FILE, index_col=[0])\n",
    "    .replace(dict(binary_label={0.0: \"neutral_post\", 1.0: \"possible_fake_news\"}))\n",
    "    .rename(columns={\"binary_label\": \"label\"})\n",
    "\n",
    "    # remove urls\n",
    "    .pipe(lambda _df: _df.assign(text=(\n",
    "        _df[\"text\"].str\n",
    "        # replace urls with special token\n",
    "        .replace(r\"https?://\\S+|www\\.\\S+\", \"[URL]\")\n",
    "    )))\n",
    "\n",
    "    # downsample to smallest category\n",
    "    .pipe(lambda _df: (\n",
    "        _df\n",
    "        .groupby(\"label\")\n",
    "        .sample(n=min(_df[\"label\"].value_counts()))\n",
    "    ))\n",
    ")\n",
    "DATA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15628, 822)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_TRAIN = DATA.sample(frac=1.0 - TEST_FRAC)\n",
    "DATA_TEST = DATA.loc[DATA.index.difference(DATA_TRAIN.index)]\n",
    "\n",
    "DATASET_TRAIN = datasets.Dataset.from_pandas(DATA_TRAIN, split=\"train\")\n",
    "DATASET_TEST = datasets.Dataset.from_pandas(DATA_TEST, split=\"test\")\n",
    "\n",
    "len(DATASET_TRAIN), len(DATASET_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6449c1347e384d50a9a2b98e3e121a0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "848a7c11613a4cb598511911e1ac880d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/433 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f46fd502c1455da010ffa64e573219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/255k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5f7d2e381164d589241e4e0b6d19312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/485k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7919bf57ea994fb09765ec0aeaee3338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/439M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "TOKENIZER = transformers.AutoTokenizer.from_pretrained(MODEL_SLUG)\n",
    "MODEL = transformers.AutoModelForSequenceClassification.from_pretrained(MODEL_SLUG, num_labels=DATA_TRAIN.label.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(sample):\n",
    "    return tokenizer(sample[\"text\"], padding=\"max_length\", truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenized_dataset = DATASET_TRAIN.map(tokenize_function, batched=True)\n",
    "test_tokenized_dataset = DATASET_TEST.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c32bb6a286c94c588c59902199132e17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57a27762820a46ed8678187f8d194a5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /media/data/models/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='211' max='210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [210/210 03:52, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy@de</th>\n",
       "      <th>F1@de</th>\n",
       "      <th>Precision@de</th>\n",
       "      <th>Recall@de</th>\n",
       "      <th>Loss@de</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.544142</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.733515</td>\n",
       "      <td>0.731690</td>\n",
       "      <td>0.739548</td>\n",
       "      <td>0.544085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.496931</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>0.778753</td>\n",
       "      <td>0.776364</td>\n",
       "      <td>0.785972</td>\n",
       "      <td>0.496048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.558303</td>\n",
       "      <td>0.769000</td>\n",
       "      <td>0.758022</td>\n",
       "      <td>0.758619</td>\n",
       "      <td>0.757467</td>\n",
       "      <td>0.556984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.914272</td>\n",
       "      <td>0.779000</td>\n",
       "      <td>0.750305</td>\n",
       "      <td>0.795366</td>\n",
       "      <td>0.740526</td>\n",
       "      <td>0.913352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.009434</td>\n",
       "      <td>0.788000</td>\n",
       "      <td>0.775940</td>\n",
       "      <td>0.779707</td>\n",
       "      <td>0.773196</td>\n",
       "      <td>1.006540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.230274</td>\n",
       "      <td>0.773000</td>\n",
       "      <td>0.751039</td>\n",
       "      <td>0.773625</td>\n",
       "      <td>0.743386</td>\n",
       "      <td>1.229162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.198938</td>\n",
       "      <td>0.779000</td>\n",
       "      <td>0.767867</td>\n",
       "      <td>0.769327</td>\n",
       "      <td>0.766615</td>\n",
       "      <td>1.195317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.220808</td>\n",
       "      <td>0.785000</td>\n",
       "      <td>0.772433</td>\n",
       "      <td>0.776749</td>\n",
       "      <td>0.769408</td>\n",
       "      <td>1.217518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.232568</td>\n",
       "      <td>0.788000</td>\n",
       "      <td>0.772118</td>\n",
       "      <td>0.783779</td>\n",
       "      <td>0.766239</td>\n",
       "      <td>1.230055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You are trying to save a non contiguous tensor: `bert.encoder.layer.0.attention.self.query.weight` which is not allowed. It either means you are trying to save tensors which are reference of each other in which case it's recommended to save only the full tensors, and reslice at load time, or simply call `.contiguous()` on your tensor to pack it before saving.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 100\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# Start Training\u001b[39;00m\n\u001b[1;32m     99\u001b[0m trainer\u001b[38;5;241m.\u001b[39madd_callback(CustomCallback(trainer)) \n\u001b[0;32m--> 100\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/transformers/trainer.py:1948\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1946\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1948\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1949\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   1950\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[1;32m   1951\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[1;32m   1952\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[1;32m   1953\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/transformers/trainer.py:2366\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2363\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[1;32m   2364\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2366\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_log_save_evaluate(tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\n\u001b[1;32m   2367\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2368\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/transformers/trainer.py:2817\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2814\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluate(trial, ignore_keys_for_eval)\n\u001b[1;32m   2816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m-> 2817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_checkpoint(model, trial, metrics\u001b[38;5;241m=\u001b[39mmetrics)\n\u001b[1;32m   2818\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_save(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/transformers/trainer.py:2896\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   2894\u001b[0m run_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_output_dir(trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[1;32m   2895\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(run_dir, checkpoint_folder)\n\u001b[0;32m-> 2896\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_model(output_dir, _internal_call\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   2898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave_only_model:\n\u001b[1;32m   2899\u001b[0m     \u001b[38;5;66;03m# Save optimizer and scheduler\u001b[39;00m\n\u001b[1;32m   2900\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_optimizer_and_scheduler(output_dir)\n",
      "File \u001b[0;32m/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/transformers/trainer.py:3464\u001b[0m, in \u001b[0;36mTrainer.save_model\u001b[0;34m(self, output_dir, _internal_call)\u001b[0m\n\u001b[1;32m   3461\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped\u001b[38;5;241m.\u001b[39msave_checkpoint(output_dir)\n\u001b[1;32m   3463\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m-> 3464\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save(output_dir)\n\u001b[1;32m   3466\u001b[0m \u001b[38;5;66;03m# Push to the Hub when `save_model` is called by the user.\u001b[39;00m\n\u001b[1;32m   3467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpush_to_hub \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _internal_call:\n",
      "File \u001b[0;32m/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/transformers/trainer.py:3535\u001b[0m, in \u001b[0;36mTrainer._save\u001b[0;34m(self, output_dir, state_dict)\u001b[0m\n\u001b[1;32m   3533\u001b[0m             torch\u001b[38;5;241m.\u001b[39msave(state_dict, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, WEIGHTS_NAME))\n\u001b[1;32m   3534\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3535\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39msave_pretrained(\n\u001b[1;32m   3536\u001b[0m         output_dir, state_dict\u001b[38;5;241m=\u001b[39mstate_dict, safe_serialization\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave_safetensors\n\u001b[1;32m   3537\u001b[0m     )\n\u001b[1;32m   3539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3540\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39msave_pretrained(output_dir)\n",
      "File \u001b[0;32m/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/transformers/modeling_utils.py:2771\u001b[0m, in \u001b[0;36mPreTrainedModel.save_pretrained\u001b[0;34m(self, save_directory, is_main_process, state_dict, save_function, push_to_hub, max_shard_size, safe_serialization, variant, token, save_peft_format, **kwargs)\u001b[0m\n\u001b[1;32m   2766\u001b[0m     gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m   2768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m safe_serialization:\n\u001b[1;32m   2769\u001b[0m     \u001b[38;5;66;03m# At some point we will need to deal better with save_function (used for TPU and other distributed\u001b[39;00m\n\u001b[1;32m   2770\u001b[0m     \u001b[38;5;66;03m# joyfulness), but for now this enough.\u001b[39;00m\n\u001b[0;32m-> 2771\u001b[0m     safe_save_file(shard, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_directory, shard_file), metadata\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m   2772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2773\u001b[0m     save_function(shard, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_directory, shard_file))\n",
      "File \u001b[0;32m/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/safetensors/torch.py:284\u001b[0m, in \u001b[0;36msave_file\u001b[0;34m(tensors, filename, metadata)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_file\u001b[39m(\n\u001b[1;32m    254\u001b[0m     tensors: Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor],\n\u001b[1;32m    255\u001b[0m     filename: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[1;32m    256\u001b[0m     metadata: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    257\u001b[0m ):\n\u001b[1;32m    258\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;124;03m    Saves a dictionary of tensors into raw bytes in safetensors format.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 284\u001b[0m     serialize_file(_flatten(tensors), filename, metadata\u001b[38;5;241m=\u001b[39mmetadata)\n",
      "File \u001b[0;32m/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/safetensors/torch.py:488\u001b[0m, in \u001b[0;36m_flatten\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m failing:\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;124m        Some tensors share memory, this will lead to duplicate memory on disk and potential differences when loading them again: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfailing\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    489\u001b[0m     k: {\n\u001b[1;32m    490\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(v\u001b[38;5;241m.\u001b[39mdtype)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    491\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m: v\u001b[38;5;241m.\u001b[39mshape,\n\u001b[1;32m    492\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: _tobytes(v, k),\n\u001b[1;32m    493\u001b[0m     }\n\u001b[1;32m    494\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m tensors\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    495\u001b[0m }\n",
      "File \u001b[0;32m/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/safetensors/torch.py:492\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m failing:\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;124m        Some tensors share memory, this will lead to duplicate memory on disk and potential differences when loading them again: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfailing\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    486\u001b[0m     )\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    489\u001b[0m     k: {\n\u001b[1;32m    490\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(v\u001b[38;5;241m.\u001b[39mdtype)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    491\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m: v\u001b[38;5;241m.\u001b[39mshape,\n\u001b[0;32m--> 492\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: _tobytes(v, k),\n\u001b[1;32m    493\u001b[0m     }\n\u001b[1;32m    494\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m tensors\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    495\u001b[0m }\n",
      "File \u001b[0;32m/opt/anaconda/envs/rcs24/lib/python3.11/site-packages/safetensors/torch.py:406\u001b[0m, in \u001b[0;36m_tobytes\u001b[0;34m(tensor, name)\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    400\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to save a sparse tensor: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` which this library does not support.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m You can make it a dense tensor before saving with `.to_dense()` but be aware this might\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m make a much larger file than needed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    403\u001b[0m     )\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mis_contiguous():\n\u001b[0;32m--> 406\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    407\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to save a non contiguous tensor: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` which is not allowed. It either means you\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    408\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m are trying to save tensors which are reference of each other in which case it\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms recommended to save\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m only the full tensors, and reslice at load time, or simply call `.contiguous()` on your tensor to\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m pack it before saving.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m     )\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;66;03m# Moving tensor to cpu before saving\u001b[39;00m\n\u001b[1;32m    414\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: You are trying to save a non contiguous tensor: `bert.encoder.layer.0.attention.self.query.weight` which is not allowed. It either means you are trying to save tensors which are reference of each other in which case it's recommended to save only the full tensors, and reslice at load time, or simply call `.contiguous()` on your tensor to pack it before saving."
     ]
    }
   ],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "    }\n",
    "\n",
    "\n",
    "# Hugging Face Trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUT_DIR,\n",
    "    evaluation_strategy=\"epoch\", \n",
    "    report_to=\"none\",\n",
    "    num_train_epochs=10,\n",
    "    #warmup_steps=500,\n",
    "    #weight_decay=0.01,\n",
    "    overwrite_output_dir=True,\n",
    "    save_total_limit=1,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
